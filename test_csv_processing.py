#!/usr/bin/env python3
"""
æµ‹è¯•CSVæ–‡ä»¶å¤„ç†åŠŸèƒ½
ç”¨ä¿®å¤åçš„ä»£ç é‡æ–°å¤„ç†ç°æœ‰çš„CSVæ–‡ä»¶
"""

import asyncio
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/root/trademe/backend/trading-service')

from app.services.okx_data_downloader import okx_data_downloader
from app.database import AsyncSessionLocal
from sqlalchemy import text
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def test_csv_processing():
    """æµ‹è¯•CSVæ–‡ä»¶å¤„ç†"""
    try:
        logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•CSVæ–‡ä»¶å¤„ç†åŠŸèƒ½")
        
        # CSVæ–‡ä»¶è·¯å¾„
        csv_file = Path("/root/trademe/backend/trading-service/data/okx_tick_data/BTC-USDT-SWAP-trades-2024-08-30-final.csv")
        output_file = Path("/root/trademe/backend/trading-service/data/okx_tick_data/BTC-USDT-SWAP-trades-2024-08-30-final2.csv")
        
        if not csv_file.exists():
            logger.error(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
            return False
        
        logger.info(f"ğŸ“‚ å¤„ç†æ–‡ä»¶: {csv_file}")
        logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {csv_file.stat().st_size / 1024 / 1024:.1f} MB")
        
        # è°ƒç”¨å¤„ç†æ–¹æ³•
        processed_records = await okx_data_downloader._process_tick_csv(csv_file, "BTC", output_file)
        
        logger.info(f"âœ… CSVå¤„ç†å®Œæˆï¼Œæ’å…¥è®°å½•æ•°: {processed_records}")
        
        # æ£€æŸ¥æ•°æ®åº“ä¸­çš„è®°å½•
        async with AsyncSessionLocal() as db:
            tick_count_query = text("SELECT COUNT(*) FROM tick_data WHERE data_source='okx_historical'")
            tick_result = await db.execute(tick_count_query)
            tick_count = tick_result.scalar()
            
            logger.info(f"ğŸ“Š æ•°æ®åº“ä¸­OKXå†å²è®°å½•æ€»æ•°: {tick_count}")
            
            if tick_count > 0:
                # æŸ¥çœ‹æœ€æ–°è®°å½•
                latest_query = text("""
                    SELECT symbol, price, volume, side, timestamp, trade_id 
                    FROM tick_data 
                    WHERE data_source='okx_historical' 
                    ORDER BY created_at DESC 
                    LIMIT 3
                """)
                latest_result = await db.execute(latest_query)
                latest_records = latest_result.fetchall()
                
                logger.info("ğŸ“‹ æœ€æ–°æ’å…¥çš„3æ¡è®°å½•:")
                for i, record in enumerate(latest_records, 1):
                    logger.info(f"   {i}. {record[0]} - ä»·æ ¼:{record[1]}, é‡:{record[2]}, æ–¹å‘:{record[3]}, æ—¶é—´æˆ³:{record[4]}, ID:{record[5]}")
        
        return processed_records > 0
        
    except Exception as e:
        logger.error(f"âŒ CSVå¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¯ å¼€å§‹CSVæ–‡ä»¶å¤„ç†æµ‹è¯•")
    logger.info("=" * 50)
    
    success = await test_csv_processing()
    
    logger.info("\n" + "=" * 50)
    if success:
        logger.info("ğŸ‰ æµ‹è¯•æˆåŠŸï¼CSVæ–‡ä»¶å¤„ç†å’Œæ•°æ®æ’å…¥åŠŸèƒ½æ­£å¸¸ï¼")
    else:
        logger.error("âŒ æµ‹è¯•å¤±è´¥ï¼éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
    
    return success

if __name__ == "__main__":
    asyncio.run(main())