"""
Claude APIå®¢æˆ·ç«¯å°è£…

æä¾›Claude AIçš„å®Œæ•´å°è£…ï¼ŒåŒ…æ‹¬ï¼š
- å¼‚æ­¥APIè°ƒç”¨
- é”™è¯¯å¤„ç†å’Œé‡è¯•
- Tokenä½¿ç”¨ç»Ÿè®¡
- æˆæœ¬æ§åˆ¶
- æ€§èƒ½ç›‘æ§
"""

import asyncio
import os
import time
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
from decimal import Decimal

import anthropic
from anthropic import AsyncAnthropic
from loguru import logger

from app.config import settings


class ClaudeUsageStats:
    """Claudeä½¿ç”¨ç»Ÿè®¡"""
    
    def __init__(self):
        self.total_requests = 0
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.total_cost = Decimal('0.00')
        self.average_response_time = 0.0
        self.error_count = 0
        
    def add_request(
        self, 
        input_tokens: int, 
        output_tokens: int, 
        response_time_ms: float,
        success: bool = True
    ):
        """æ·»åŠ è¯·æ±‚ç»Ÿè®¡"""
        self.total_requests += 1
        
        if success:
            self.total_input_tokens += input_tokens
            self.total_output_tokens += output_tokens
            
            # Claude 4 Sonnet å®šä»· (2025å¹´ä»·æ ¼ï¼Œä¸3.5ç›¸åŒ)
            input_cost = Decimal(str(input_tokens)) * Decimal('3.0') / Decimal('1000000')  # $3/1M tokens
            output_cost = Decimal(str(output_tokens)) * Decimal('15.0') / Decimal('1000000')  # $15/1M tokens
            self.total_cost += input_cost + output_cost
            
            # æ›´æ–°å¹³å‡å“åº”æ—¶é—´
            self.average_response_time = (
                (self.average_response_time * (self.total_requests - 1) + response_time_ms) / 
                self.total_requests
            )
        else:
            self.error_count += 1
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_requests": self.total_requests,
            "successful_requests": self.total_requests - self.error_count,
            "error_count": self.error_count,
            "success_rate": (self.total_requests - self.error_count) / max(self.total_requests, 1),
            "total_input_tokens": self.total_input_tokens,
            "total_output_tokens": self.total_output_tokens,
            "total_tokens": self.total_input_tokens + self.total_output_tokens,
            "total_cost_usd": float(self.total_cost),
            "average_response_time_ms": self.average_response_time,
            "cost_per_request": float(self.total_cost) / max(self.total_requests - self.error_count, 1)
        }


class ClaudeClient:
    """Claude APIå®¢æˆ·ç«¯å°è£…ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–Claudeå®¢æˆ·ç«¯"""
        # æ”¯æŒå¤šç§API keyç¯å¢ƒå˜é‡
        self.api_key = (settings.claude_auth_token or 
                       settings.claude_api_key or 
                       os.getenv("ANTHROPIC_AUTH_TOKEN") or 
                       os.getenv("CLAUDE_API_KEY"))
        
        # æ”¯æŒå¤šç§base_urlç¯å¢ƒå˜é‡
        self.base_url = (settings.anthropic_base_url or 
                        settings.claude_base_url or 
                        os.getenv("ANTHROPIC_BASE_URL") or 
                        os.getenv("CLAUDE_BASE_URL"))
        
        self.model = settings.claude_model
        self.max_tokens = settings.claude_max_tokens
        self.timeout = settings.claude_timeout
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯ (åŒ…å«é”™è¯¯å¤„ç†)
        if self.api_key and self.api_key != "your_claude_api_key_here":
            try:
                # æ ¹æ®anthropicåº“ç‰ˆæœ¬ä½¿ç”¨åˆé€‚çš„å‚æ•°
                client_kwargs = {
                    "api_key": self.api_key,
                    "timeout": self.timeout
                }
                
                # å¦‚æœæœ‰è‡ªå®šä¹‰base_urlï¼Œåˆ™ä½¿ç”¨
                if self.base_url:
                    client_kwargs["base_url"] = self.base_url
                    logger.info(f"ä½¿ç”¨è‡ªå®šä¹‰Claude APIç«¯ç‚¹: {self.base_url}")
                
                self.client = AsyncAnthropic(**client_kwargs)
                self.enabled = True
                logger.info("Claudeå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"Claudeå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿæ¨¡å¼: {str(e)}")
                self.client = None
                self.enabled = False
        else:
            self.client = None
            self.enabled = False
            logger.warning("Claude APIå¯†é’¥æœªè®¾ç½®ï¼ŒAIåŠŸèƒ½å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        
        # ä½¿ç”¨ç»Ÿè®¡
        self.stats = ClaudeUsageStats()
        
        # é‡è¯•é…ç½®
        self.max_retries = 3
        self.retry_delay = 1.0  # ç§’
        
        logger.info(f"Claudeå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ - æ¨¡å‹: {self.model}, å¯ç”¨çŠ¶æ€: {self.enabled}")
    
    async def _make_request(
        self,
        messages: List[Dict[str, str]],
        system_prompt: Optional[str] = None,
        max_tokens: Optional[int] = None,
        temperature: float = 0.7,
        retry_count: int = 0,
        api_key: Optional[str] = None
    ) -> Tuple[str, Dict[str, Any]]:
        """æ‰§è¡ŒClaude APIè¯·æ±‚"""
        
        if not self.enabled:
            # æ¨¡æ‹Ÿæ¨¡å¼
            return await self._mock_response(messages, system_prompt)
        
        start_time = time.time()
        request_max_tokens = max_tokens or self.max_tokens
        
        try:
            # å¦‚æœæä¾›äº†åŠ¨æ€APIå¯†é’¥ï¼Œåˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯
            if api_key and api_key != self.api_key:
                temp_client_kwargs = {
                    "api_key": api_key,
                    "timeout": self.timeout
                }
                if self.base_url:
                    temp_client_kwargs["base_url"] = self.base_url
                
                temp_client = AsyncAnthropic(**temp_client_kwargs)
                client_to_use = temp_client
            else:
                client_to_use = self.client
            
            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                "model": self.model,
                "max_tokens": request_max_tokens,
                "temperature": temperature,
                "messages": messages
            }
            
            if system_prompt:
                request_params["system"] = system_prompt
            
            # å‘é€è¯·æ±‚
            response = await client_to_use.messages.create(**request_params)
            
            # è®¡ç®—å“åº”æ—¶é—´
            response_time_ms = (time.time() - start_time) * 1000
            
            # æå–å“åº”å†…å®¹
            content = ""
            if response.content and len(response.content) > 0:
                content = response.content[0].text
            
            # ç»Ÿè®¡ä¿¡æ¯
            usage_info = {
                "input_tokens": response.usage.input_tokens,
                "output_tokens": response.usage.output_tokens,
                "total_tokens": response.usage.input_tokens + response.usage.output_tokens,
                "model": response.model,
                "response_time_ms": response_time_ms
            }
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats.add_request(
                input_tokens=response.usage.input_tokens,
                output_tokens=response.usage.output_tokens,
                response_time_ms=response_time_ms,
                success=True
            )
            
            logger.debug(f"Claude APIè¯·æ±‚æˆåŠŸ - Tokenä½¿ç”¨: {usage_info['total_tokens']}, å“åº”æ—¶é—´: {response_time_ms:.2f}ms")
            
            return content, usage_info
            
        except anthropic.RateLimitError as e:
            logger.warning(f"Claude APIé¢‘ç‡é™åˆ¶: {str(e)}")
            if retry_count < self.max_retries:
                await asyncio.sleep(self.retry_delay * (2 ** retry_count))  # æŒ‡æ•°é€€é¿
                return await self._make_request(messages, system_prompt, max_tokens, temperature, retry_count + 1, api_key)
            raise
            
        except anthropic.APITimeoutError as e:
            logger.warning(f"Claude APIè¶…æ—¶: {str(e)}")
            if retry_count < self.max_retries:
                await asyncio.sleep(self.retry_delay)
                return await self._make_request(messages, system_prompt, max_tokens, temperature, retry_count + 1, api_key)
            raise
            
        except anthropic.APIError as e:
            error_message = str(e)
            logger.error(f"Claude APIé”™è¯¯: {error_message}")
            
            # ç‰¹æ®Šå¤„ç†ç½‘å…³è¶…æ—¶é”™è¯¯ (504 Gateway Timeout)
            if "504" in error_message or "Gateway time-out" in error_message:
                logger.warning(f"Claude APIä»£ç†æœåŠ¡ç½‘å…³è¶…æ—¶ï¼Œå°è¯•é‡è¯• (é‡è¯•æ¬¡æ•°: {retry_count}/{self.max_retries})")
                if retry_count < self.max_retries:
                    # ç½‘å…³è¶…æ—¶ä½¿ç”¨æ›´é•¿çš„é‡è¯•å»¶è¿Ÿ
                    await asyncio.sleep(self.retry_delay * 2)  
                    return await self._make_request(messages, system_prompt, max_tokens, temperature, retry_count + 1, api_key)
                # è¶…è¿‡é‡è¯•æ¬¡æ•°åæŠ›å‡ºç”¨æˆ·å‹å¥½çš„é”™è¯¯
                raise Exception("Claude AIæœåŠ¡ç¹å¿™ï¼Œè¯·ç¨åé‡è¯•")
            
            # ç‰¹æ®Šå¤„ç†503æœåŠ¡ä¸å¯ç”¨é”™è¯¯
            if "503" in error_message or "Service Unavailable" in error_message:
                logger.warning("Claude APIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨")
                raise Exception("AIæœåŠ¡æš‚æ—¶ç»´æŠ¤ä¸­ï¼Œè¯·ç¨åé‡è¯•")
            
            # ç‰¹æ®Šå¤„ç†è®¤è¯é”™è¯¯
            if "401" in error_message or "authentication" in error_message.lower():
                logger.error("Claude APIè®¤è¯å¤±è´¥")
                raise Exception("AIæœåŠ¡è®¤è¯å¤±è´¥ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
            
            self.stats.add_request(0, 0, 0, success=False)
            raise Exception(f"AIæœåŠ¡é”™è¯¯ï¼š{error_message}")
            
        except Exception as e:
            error_message = str(e)
            logger.error(f"Claudeå®¢æˆ·ç«¯æœªçŸ¥é”™è¯¯: {error_message}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œè¿æ¥é”™è¯¯
            if any(keyword in error_message.lower() for keyword in ["connection", "network", "timeout", "unreachable"]):
                if retry_count < self.max_retries:
                    logger.warning(f"ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œå°è¯•é‡è¯• (é‡è¯•æ¬¡æ•°: {retry_count}/{self.max_retries})")
                    await asyncio.sleep(self.retry_delay * 1.5)
                    return await self._make_request(messages, system_prompt, max_tokens, temperature, retry_count + 1, api_key)
                raise Exception("ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®")
            
            self.stats.add_request(0, 0, 0, success=False)
            
            # å¦‚æœé”™è¯¯æ¶ˆæ¯å·²ç»æ˜¯ç”¨æˆ·å‹å¥½çš„ï¼Œç›´æ¥ä½¿ç”¨
            if error_message.startswith(("AIæœåŠ¡", "Claude AI", "ç½‘ç»œè¿æ¥")):
                raise
            else:
                raise Exception("AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•")
    
    async def _mock_response(
        self, 
        messages: List[Dict[str, str]], 
        system_prompt: Optional[str] = None
    ) -> Tuple[str, Dict[str, Any]]:
        """æ¨¡æ‹ŸClaudeå“åº” (å¼€å‘æµ‹è¯•ç”¨)"""
        
        # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        await asyncio.sleep(0.5)
        
        last_message = messages[-1]["content"] if messages else ""
        
        # ç®€å•çš„æ¨¡æ‹Ÿå“åº”é€»è¾‘ (ä»…åœ¨APIå¯†é’¥æœªé…ç½®æ—¶ä½¿ç”¨)
        if "ç­–ç•¥" in last_message or "strategy" in last_message.lower():
            mock_content = """
# ç®€å•ç§»åŠ¨å¹³å‡ç­–ç•¥

è¿™æ˜¯ä¸€ä¸ªåŸºäºç§»åŠ¨å¹³å‡çº¿äº¤å‰çš„ç®€å•ç­–ç•¥ç¤ºä¾‹ï¼š

```python
class SimpleMaStrategy(BaseStrategy):
    def __init__(self):
        super().__init__()
        self.short_period = 5
        self.long_period = 20
    
    def on_bar(self, bar):
        # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
        short_ma = self.sma(self.short_period)
        long_ma = self.sma(self.long_period)
        
        # äº¤æ˜“ä¿¡å·
        if short_ma > long_ma and not self.position:
            self.buy()  # é‡‘å‰ä¹°å…¥
        elif short_ma < long_ma and self.position:
            self.sell()  # æ­»å‰å–å‡º
```

è¿™æ˜¯ä¸€ä¸ªåŸºç¡€çš„è¶‹åŠ¿è·Ÿéšç­–ç•¥ï¼Œé€‚åˆåˆå­¦è€…ç†è§£äº¤æ˜“ç­–ç•¥çš„åŸºæœ¬ç»“æ„ã€‚
            """
        elif "åˆ†æ" in last_message or "analysis" in last_message.lower():
            mock_content = """
åŸºäºå½“å‰å¸‚åœºæ•°æ®åˆ†æ:

## å¸‚åœºæ¦‚å†µ
- è¶‹åŠ¿: éœ‡è¡ä¸Šæ¶¨
- æ³¢åŠ¨ç‡: ä¸­ç­‰
- æˆäº¤é‡: æ­£å¸¸

## æŠ€æœ¯æŒ‡æ ‡
- RSI: 65 (ç•¥æ˜¾å¼ºåŠ¿)
- MACD: é‡‘å‰å½¢æ€
- æ”¯æ’‘ä½: $45,000
- é˜»åŠ›ä½: $52,000

## å»ºè®®
1. å¯ä»¥è€ƒè™‘è½»ä»“åšå¤š
2. è®¾ç½®æ­¢æŸåœ¨$46,000
3. ç›®æ ‡ä»·ä½$50,000

è¯·æ³¨æ„é£é™©ç®¡ç†ï¼Œåˆç†é…ç½®ä»“ä½å¤§å°ã€‚
            """
        else:
            mock_content = f"""
æ‚¨å¥½ï¼æˆ‘æ˜¯Trademeçš„AIäº¤æ˜“åŠ©æ‰‹ã€‚

æ‚¨çš„é—®é¢˜: "{last_message}"

æ„Ÿè°¢æ‚¨çš„æé—®ï¼æˆ‘å¯ä»¥å¸®åŠ©æ‚¨ï¼š

- ğŸ“ˆ ç”Ÿæˆä¸ªæ€§åŒ–äº¤æ˜“ç­–ç•¥ä»£ç 
- ğŸ“Š è¿›è¡Œä¸“ä¸šå¸‚åœºæ•°æ®åˆ†æ
- ğŸ’¡ è§£è¯»å’Œä¼˜åŒ–å›æµ‹ç»“æœ  
- ğŸ¤– å›ç­”å„ç±»é‡åŒ–äº¤æ˜“é—®é¢˜
- ğŸ” æä¾›æŠ€æœ¯æŒ‡æ ‡ä½¿ç”¨å»ºè®®
- âš¡ å®æ—¶äº¤æ˜“ä¿¡å·åˆ†æ

è¯·å‘Šè¯‰æˆ‘æ‚¨å…·ä½“éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Œæˆ‘ä¼šä¸ºæ‚¨æä¾›è¯¦ç»†çš„ä¸“ä¸šå»ºè®®ã€‚
            """
        
        # æ¨¡æ‹Ÿä½¿ç”¨ç»Ÿè®¡
        mock_usage = {
            "input_tokens": len(last_message) // 4,  # ç²—ç•¥ä¼°ç®—
            "output_tokens": len(mock_content) // 4,
            "total_tokens": (len(last_message) + len(mock_content)) // 4,
            "model": "claude-3-5-sonnet-mock",
            "response_time_ms": 500.0
        }
        
        self.stats.add_request(
            input_tokens=mock_usage["input_tokens"],
            output_tokens=mock_usage["output_tokens"],
            response_time_ms=mock_usage["response_time_ms"],
            success=True
        )
        
        return mock_content, mock_usage
    
    async def chat_completion(
        self,
        messages: List[Dict[str, str]],
        system_prompt: Optional[str] = None,
        max_tokens: Optional[int] = None,
        temperature: float = 0.7,
        api_key: Optional[str] = None
    ) -> Dict[str, Any]:
        """èŠå¤©å®ŒæˆAPI"""
        
        try:
            content, usage_info = await self._make_request(
                messages=messages,
                system_prompt=system_prompt,
                max_tokens=max_tokens,
                temperature=temperature,
                api_key=api_key
            )
            
            return {
                "content": content,
                "usage": usage_info,
                "model": usage_info.get("model", self.model),
                "created_at": datetime.utcnow().isoformat(),
                "success": True
            }
            
        except Exception as e:
            logger.error(f"èŠå¤©å®Œæˆå¤±è´¥: {str(e)}")
            return {
                "content": f"æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(e)}",
                "usage": {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0},
                "model": self.model,
                "created_at": datetime.utcnow().isoformat(),
                "success": False,
                "error": str(e)
            }
    
    async def generate_strategy_code(
        self,
        description: str,
        indicators: List[str],
        timeframe: str = "1h",
        risk_level: str = "medium"
    ) -> Dict[str, Any]:
        """ç”Ÿæˆç­–ç•¥ä»£ç """
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡åŒ–äº¤æ˜“ç­–ç•¥å¼€å‘ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”ŸæˆPythonäº¤æ˜“ç­–ç•¥ä»£ç ã€‚

è¦æ±‚ï¼š
1. ä½¿ç”¨BaseStrategyç±»ä½œä¸ºåŸºç¡€
2. ä»£ç å¿…é¡»å®‰å…¨ï¼Œä¸åŒ…å«ä»»ä½•å±é™©å‡½æ•°æˆ–ç½‘ç»œè¯·æ±‚
3. æ·»åŠ è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Š
4. æä¾›ç­–ç•¥è¯´æ˜å’Œé£é™©æç¤º
5. åŒ…å«åˆç†çš„å‚æ•°è®¾ç½®

è¾“å‡ºæ ¼å¼ï¼š
- ç­–ç•¥ä»£ç  (Python)
- ç­–ç•¥è¯´æ˜
- å‚æ•°è¯´æ˜
- é£é™©æç¤º"""
        
        user_message = f"""
è¯·ç”Ÿæˆä¸€ä¸ªäº¤æ˜“ç­–ç•¥ï¼Œè¦æ±‚å¦‚ä¸‹ï¼š

ç­–ç•¥æè¿°: {description}
æŠ€æœ¯æŒ‡æ ‡: {', '.join(indicators)}
æ—¶é—´å‘¨æœŸ: {timeframe}
é£é™©çº§åˆ«: {risk_level}

è¯·ç¡®ä¿ä»£ç çš„å®‰å…¨æ€§å’Œå®ç”¨æ€§ã€‚
        """
        
        messages = [{"role": "user", "content": user_message}]
        
        return await self.chat_completion(
            messages=messages,
            system_prompt=system_prompt,
            temperature=0.3  # ä»£ç ç”Ÿæˆä½¿ç”¨è¾ƒä½æ¸©åº¦
        )
    
    async def analyze_market_data(
        self,
        market_data: Dict[str, Any],
        symbols: List[str],
        analysis_type: str = "technical",
        api_key: Optional[str] = None
    ) -> Dict[str, Any]:
        """åˆ†æå¸‚åœºæ•°æ®"""
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„åŠ å¯†è´§å¸å¸‚åœºåˆ†æå¸ˆã€‚è¯·åŸºäºæä¾›çš„å¸‚åœºæ•°æ®è¿›è¡Œä¸“ä¸šåˆ†æã€‚

åˆ†æè¦æ±‚ï¼š
1. åŸºäºæŠ€æœ¯åˆ†ææä¾›å®¢è§‚åˆ¤æ–­
2. åŒ…å«é£é™©è¯„ä¼°å’Œæ¦‚ç‡åˆ†æ
3. æä¾›å…·ä½“çš„äº¤æ˜“å»ºè®®
4. ä½¿ç”¨ä¸­æ–‡è¾“å‡ºä¸“ä¸šæŠ¥å‘Š
5. é¿å…è¿‡åº¦ä¹è§‚æˆ–æ‚²è§‚çš„è¡¨è¿°"""
        
        user_message = f"""
è¯·åˆ†æä»¥ä¸‹å¸‚åœºæ•°æ®ï¼š

åˆ†æç±»å‹: {analysis_type}
å…³æ³¨å¸ç§: {', '.join(symbols)}
å¸‚åœºæ•°æ®: {str(market_data)[:1000]}...

è¯·æä¾›ä¸“ä¸šçš„å¸‚åœºåˆ†æå’Œå»ºè®®ã€‚
        """
        
        messages = [{"role": "user", "content": user_message}]
        
        return await self.chat_completion(
            messages=messages,
            system_prompt=system_prompt,
            temperature=0.5,
            api_key=api_key
        )
    
    def get_usage_stats(self) -> Dict[str, Any]:
        """è·å–ä½¿ç”¨ç»Ÿè®¡"""
        return self.stats.get_stats()
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡"""
        self.stats = ClaudeUsageStats()
        logger.info("Claudeä½¿ç”¨ç»Ÿè®¡å·²é‡ç½®")


# å…¨å±€Claudeå®¢æˆ·ç«¯å®ä¾‹
claude_client = ClaudeClient()