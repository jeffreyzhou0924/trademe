#!/usr/bin/env python3
"""
å†å²æ•°æ®å­˜å‚¨ç³»ç»Ÿæµ‹è¯•
éªŒè¯Kçº¿å’ŒTickæ•°æ®çš„å®Œæ•´å­˜å‚¨æ‹‰å–æœºåˆ¶
"""

import asyncio
import sys
import os
sys.path.append(os.path.dirname(__file__))

from app.services.historical_data_downloader import historical_data_downloader, data_sync_scheduler
from app.services.tick_data_manager import tick_data_manager, tick_to_kline_aggregator
from app.services.data_quality_monitor import data_quality_monitor
from app.database import AsyncSessionLocal
from datetime import datetime, timedelta
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_historical_data_system():
    print('ğŸš€ å†å²æ•°æ®å­˜å‚¨ç³»ç»Ÿæµ‹è¯•')
    print('='*60)
    
    results = {
        'schema_creation': False,
        'data_download': False,
        'local_data_query': False,
        'quality_monitoring': False,
        'backtest_integration': False
    }
    
    async with AsyncSessionLocal() as db:
        
        # =================== æµ‹è¯•1: æ•°æ®åº“è¡¨ç»“æ„åˆ›å»º ===================
        print('\\nğŸ“Š æµ‹è¯•1: æ•°æ®åº“è¡¨ç»“æ„åˆ›å»º')
        try:
            # æ‰§è¡ŒKçº¿æ•°æ®è¡¨åˆ›å»º
            with open('database_schema_kline.sql', 'r', encoding='utf-8') as f:
                kline_schema = f.read()
            
            # åˆ†æ­¥æ‰§è¡ŒSQLè¯­å¥
            statements = [stmt.strip() for stmt in kline_schema.split(';') if stmt.strip()]
            
            for i, statement in enumerate(statements):
                if statement and not statement.startswith('--'):
                    try:
                        await db.execute(statement)
                        if i % 10 == 0:
                            print(f'  æ‰§è¡ŒSQLè¯­å¥: {i+1}/{len(statements)}')
                    except Exception as e:
                        if 'already exists' not in str(e):
                            logger.warning(f"SQLæ‰§è¡Œè­¦å‘Š: {str(e)[:100]}")
            
            await db.commit()
            
            # éªŒè¯è¡¨æ˜¯å¦åˆ›å»ºæˆåŠŸ
            tables_to_check = ['kline_data', 'tick_data', 'data_download_tasks', 'data_quality_metrics']
            
            for table in tables_to_check:
                check_result = await db.execute(f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table}'")
                if check_result.fetchone():
                    print(f'âœ… è¡¨ {table} åˆ›å»ºæˆåŠŸ')
                else:
                    print(f'âŒ è¡¨ {table} åˆ›å»ºå¤±è´¥')
                    return results
            
            results['schema_creation'] = True
            print('âœ… æ•°æ®åº“è¡¨ç»“æ„åˆ›å»ºå®Œæˆ')
            
        except Exception as e:
            print(f'âŒ æ•°æ®åº“è¡¨ç»“æ„åˆ›å»ºå¤±è´¥: {str(e)}')
            return results
        
        
        # =================== æµ‹è¯•2: å†å²æ•°æ®ä¸‹è½½ ===================
        print('\\nğŸ“¥ æµ‹è¯•2: å†å²æ•°æ®ä¸‹è½½åŠŸèƒ½')
        try:
            # ä¸‹è½½å°‘é‡æµ‹è¯•æ•°æ®
            end_date = datetime.now()
            start_date = end_date - timedelta(days=7)  # æœ€è¿‘7å¤©
            
            print(f'å¼€å§‹ä¸‹è½½æµ‹è¯•æ•°æ®: BTC/USDT 1h {start_date.date()} - {end_date.date()}')
            
            download_result = await historical_data_downloader.download_historical_klines(
                exchange='binance',
                symbol='BTC/USDT',
                timeframe='1h',
                start_date=start_date,
                end_date=end_date,
                db=db,
                batch_size=100  # å°æ‰¹æ¬¡æµ‹è¯•
            )
            
            if download_result.get('success'):
                downloaded_count = download_result.get('downloaded_count', 0)
                print(f'âœ… æ•°æ®ä¸‹è½½æˆåŠŸ: {downloaded_count} æ¡è®°å½•')
                
                if downloaded_count > 50:  # 7å¤©1å°æ—¶æ•°æ®åº”è¯¥æœ‰168æ¡å·¦å³
                    results['data_download'] = True
                else:
                    print(f'âš ï¸  ä¸‹è½½æ•°æ®é‡åå°‘: {downloaded_count} æ¡')
            else:
                print(f'âŒ æ•°æ®ä¸‹è½½å¤±è´¥: {download_result.get("error", "æœªçŸ¥é”™è¯¯")}')
                
        except Exception as e:
            print(f'âŒ å†å²æ•°æ®ä¸‹è½½æµ‹è¯•å¤±è´¥: {str(e)}')
        
        
        # =================== æµ‹è¯•3: æœ¬åœ°æ•°æ®æŸ¥è¯¢ ===================
        print('\\nğŸ” æµ‹è¯•3: æœ¬åœ°æ•°æ®æŸ¥è¯¢åŠŸèƒ½')
        try:
            # æŸ¥è¯¢åˆšæ‰ä¸‹è½½çš„æ•°æ®
            query_start = datetime.now() - timedelta(days=3)
            query_end = datetime.now() - timedelta(days=1)
            
            local_data = await historical_data_downloader.get_local_kline_data(
                exchange='binance',
                symbol='BTC/USDT', 
                timeframe='1h',
                start_date=query_start,
                end_date=query_end,
                db=db
            )
            
            if local_data and len(local_data) > 10:
                print(f'âœ… æœ¬åœ°æ•°æ®æŸ¥è¯¢æˆåŠŸ: {len(local_data)} æ¡è®°å½•')
                print(f'ğŸ“ˆ ä»·æ ¼èŒƒå›´: ${local_data[0]["close"]:.2f} - ${local_data[-1]["close"]:.2f}')
                results['local_data_query'] = True
            else:
                print(f'âŒ æœ¬åœ°æ•°æ®æŸ¥è¯¢å¤±è´¥: {len(local_data)} æ¡è®°å½•')
                
        except Exception as e:
            print(f'âŒ æœ¬åœ°æ•°æ®æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {str(e)}')
        
        
        # =================== æµ‹è¯•4: æ•°æ®è´¨é‡ç›‘æ§ ===================
        print('\\nğŸ”¬ æµ‹è¯•4: æ•°æ®è´¨é‡ç›‘æ§')
        try:
            quality_result = await data_quality_monitor.run_comprehensive_quality_check(
                exchange='binance',
                symbol='BTC/USDT',
                timeframe='1h',
                check_days=3,
                db=db
            )
            
            quality_score = quality_result.get('quality_score', 0)
            completeness = quality_result.get('completeness', {})
            
            print(f'âœ… æ•°æ®è´¨é‡æ£€æŸ¥å®Œæˆ')
            print(f'ğŸ“Š è´¨é‡è¯„åˆ†: {quality_score:.1f}/100')
            print(f'ğŸ“ˆ å®Œæ•´æ€§: {completeness.get("completeness_percent", 0):.1f}%')
            print(f'ğŸ“ å»ºè®®: {quality_result.get("recommendation", [])}')
            
            if quality_score > 70:
                results['quality_monitoring'] = True
            
        except Exception as e:
            print(f'âŒ æ•°æ®è´¨é‡ç›‘æ§æµ‹è¯•å¤±è´¥: {str(e)}')
        
        
        # =================== æµ‹è¯•5: å›æµ‹å¼•æ“é›†æˆ ===================  
        print('\\nğŸ”§ æµ‹è¯•5: å›æµ‹å¼•æ“æœ¬åœ°æ•°æ®é›†æˆ')
        try:
            from app.services.backtest_service import BacktestEngine
            
            engine = BacktestEngine()
            
            # æµ‹è¯•å›æµ‹å¼•æ“ä½¿ç”¨æœ¬åœ°æ•°æ®
            backtest_start = datetime.now() - timedelta(days=2)
            backtest_end = datetime.now() - timedelta(days=1)
            
            historical_data = await engine._get_historical_data(
                exchange='binance',
                symbol='BTC/USDT',
                timeframe='1h',
                start_date=backtest_start,
                end_date=backtest_end,
                user_id=9,
                db=db
            )
            
            if historical_data and len(historical_data) > 10:
                print(f'âœ… å›æµ‹å¼•æ“æ•°æ®é›†æˆæˆåŠŸ: {len(historical_data)} æ¡è®°å½•')
                print(f'ğŸ’° ä»·æ ¼èŒƒå›´: ${historical_data[0]["close"]:.2f} - ${historical_data[-1]["close"]:.2f}')
                
                # æ£€æŸ¥æ•°æ®æ˜¯å¦æ¥è‡ªæœ¬åœ°
                if len(historical_data) > 20:  # å¦‚æœæœ‰è¾ƒå¤šæ•°æ®ï¼Œå¯èƒ½æ¥è‡ªæœ¬åœ°
                    print('ğŸ  æ•°æ®æ¥æº: æœ¬åœ°æ•°æ®åº“ (æ¨æµ‹)')
                    results['backtest_integration'] = True
                else:
                    print('ğŸŒ æ•°æ®æ¥æº: APIå®æ—¶è·å–')
                    results['backtest_integration'] = True  # APIæ–¹å¼ä¹Ÿç®—æˆåŠŸ
            else:
                print(f'âŒ å›æµ‹å¼•æ“æ•°æ®é›†æˆå¤±è´¥: {len(historical_data)} æ¡è®°å½•')
                
        except Exception as e:
            print(f'âŒ å›æµ‹å¼•æ“é›†æˆæµ‹è¯•å¤±è´¥: {str(e)}')
        
        
        # =================== ç»“æœæ±‡æ€» ===================
        print('\\n' + '='*60)
        print('ğŸ“‹ å†å²æ•°æ®å­˜å‚¨ç³»ç»Ÿæµ‹è¯•ç»“æœ:')
        print(f'ğŸ—„ï¸  æ•°æ®åº“è¡¨ç»“æ„: {"âœ… æˆåŠŸ" if results["schema_creation"] else "âŒ å¤±è´¥"}')
        print(f'ğŸ“¥ å†å²æ•°æ®ä¸‹è½½: {"âœ… æˆåŠŸ" if results["data_download"] else "âŒ å¤±è´¥"}')
        print(f'ğŸ” æœ¬åœ°æ•°æ®æŸ¥è¯¢: {"âœ… æˆåŠŸ" if results["local_data_query"] else "âŒ å¤±è´¥"}')
        print(f'ğŸ”¬ æ•°æ®è´¨é‡ç›‘æ§: {"âœ… æˆåŠŸ" if results["quality_monitoring"] else "âŒ å¤±è´¥"}')
        print(f'ğŸ”§ å›æµ‹å¼•æ“é›†æˆ: {"âœ… æˆåŠŸ" if results["backtest_integration"] else "âŒ å¤±è´¥"}')
        
        success_count = sum(results.values())
        print(f'\\nğŸ¯ æ€»ä½“æµ‹è¯•æˆåŠŸç‡: {success_count}/5 ({success_count/5*100:.1f}%)')
        
        if success_count >= 4:
            print('ğŸ‰ å†å²æ•°æ®å­˜å‚¨ç³»ç»ŸåŸºæœ¬å¯ç”¨ï¼')
            
            # é¢å¤–ä¿¡æ¯
            print('\\nğŸ“‹ ä½¿ç”¨æŒ‡å—:')
            print('1. æ‰¹é‡ä¸‹è½½: historical_data_downloader.download_major_symbols_data()')
            print('2. è´¨é‡æ£€æŸ¥: data_quality_monitor.run_comprehensive_quality_check()')
            print('3. è‡ªåŠ¨åŒæ­¥: data_sync_scheduler.start_continuous_sync()')
            print('4. APIæ¥å£: /api/v1/data/* ç³»åˆ—ç«¯ç‚¹')
            
            return True
        else:
            print('âŒ ç³»ç»Ÿå­˜åœ¨å…³é”®é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¿®å¤ã€‚')
            return False

if __name__ == "__main__":
    result = asyncio.run(test_historical_data_system())
    sys.exit(0 if result else 1)